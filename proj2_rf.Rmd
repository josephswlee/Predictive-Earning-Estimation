---
title: "Untitled"
author: ""
date: "4/24/2022"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, warning=FALSE}
library(randomForest)
library(rio)
library(plyr)
library(tidyverse)
library(rpart)
library(psych)
library(pROC)
library(rpart.plot)
library(rattle)
library(caret)
library(mlbench)
library(MLmetrics)
library(ROCR)
library(mltools)
library(data.table)
library(plotly)
```

```{r}
df <- read.csv("~/Dev/DS4002/4002_handsOn/project2/mainsheet.csv")

#View(df)

df$Stock.Price.Delta.Between.Dates

range(df$Stock.Price.Delta.Between.Dates)

(column_index <- tibble(colnames(eda)))

#View(column_index)

range(df$Subjectivity)

median(df$Stock.Price.Delta.Between.Dates)

str(df)

eda <- df

eda[, c(1,2)] <- lapply(eda[, c(1,2)], as.factor)

eda[, c(6,8)] <- lapply(eda[, c(6,8)], as.character)

eda$Release.Date <- as.Date(eda$Release.Date, "%m/%d/%y")
eda$Call.Date <- as.Date(eda$Call.Date, "%m/%d/%y")


str(eda)

eda <- eda[, -c(19)]

#View(eda)

eda$Stock.Price.Delta.Between.Dates <- ifelse(eda$Stock.Price.Delta.Between.Dates >-0.00225, 1, 0)

eda <- eda[, -c(6,8)]
0.512-0.051
```

```{r}
sample_rows = 1:nrow(eda)

set.seed(1984) #sample(x, size, replace = FALSE, prob = NULL)
test_rows = sample(sample_rows,
                   dim(eda)[1]*.10, #start with 10% of our dataset, could do 20%
                   # but random forest does require more training data because of the 
                   # sampling so 90% might be a better approach with this small of a dataset
                   replace = FALSE)# We don't want duplicate samples

# Partition the data between training and test sets using the row numbers the
# sample() function selected.
eda_train = eda[-test_rows,]
eda_test = eda[test_rows,]

dim(eda_train)
```

```{r}
###### for tune

set.seed(1984) #sample(x, size, replace = FALSE, prob = NULL)
test_rows = sample(sample_rows,
                   dim(eda_test)[1]*.50, #start with 10% of our dataset, could do 20%
                   # but random forest does require more training data because of the 
                   # sampling so 90% might be a better approach with this small of a dataset
                   replace = FALSE)# We don't want duplicate samples

tune = eda_test[-test_rows,]
test = eda_test[test_rows,]

set.seed(1984) #sample(x, size, replace = FALSE, prob = NULL)
test_rows = sample(sample_rows,
                   dim(tune)[1]*.50, #start with 10% of our dataset, could do 20%
                   # but random forest does require more training data because of the 
                   # sampling so 90% might be a better approach with this small of a dataset
                   replace = FALSE)# We don't want duplicate samples

x_tune = tune[-test_rows,]
y_tune = tune[test_rows,]
```

```{r}
mytry_tune <- function(x){
  xx <- dim(x)[2]-1
  sqrt(xx)
}
mytry_tune(eda)
```
4.472

```{r}
set.seed(2023)  

eda_RF = randomForest(as.factor(Stock.Price.Delta.Between.Dates)~.,   
                            eda_train,    
                            ntree = 500,      
                            mtry = 4,         
                            replace = TRUE,   
                            sampsize = 44,    
                            nodesize = 5,    
                            importance = TRUE, 
                            proximity = FALSE, 
                            norm.votes = TRUE,
                            do.trace = TRUE,  
                            keep.forest = TRUE,
                            keep.inbag = TRUE)   
```


```{r}
eda_RF
```

```{r}
set.seed(2023)  

eda_RF2 = randomForest(as.factor(Stock.Price.Delta.Between.Dates)~.,   
                            eda_train,    
                            ntree = 2500,      
                            mtry = 4,         
                            replace = TRUE,   
                            sampsize = 44,    
                            nodesize = 10,    
                            importance = TRUE, 
                            proximity = FALSE, 
                            norm.votes = TRUE,
                            do.trace = TRUE,  
                            keep.forest = TRUE,
                            keep.inbag = TRUE)   
```

```{r}
eda_RF2
```

Call:
 randomForest(formula = as.factor(Stock.Price.Delta.Between.Dates) ~      ., data = eda_train, ntree = 5500, mtry = 4, replace = TRUE,      sampsize = 44, nodesize = 10, importance = TRUE, proximity = FALSE,      norm.votes = TRUE, do.trace = TRUE, keep.forest = TRUE, keep.inbag = TRUE) 
               Type of random forest: classification
                     Number of trees: 5500
No. of variables tried at each split: 4

        OOB estimate of  error rate: 59.09%
Confusion matrix: 
   0  1 class.error
0  8 14   0.6363636
1 12 10   0.5454545

*Trying KNN*

```{r}
library(tidyverse)
library(plotly)
library(htmltools)
library(devtools)
library(caret)
library(NbClust)
library(corrplot)

```

```{r}
edak <- read_csv("~/Dev/DS4002/4002_handsOn/project2/mainsheet.csv")

View(edak)
(edak_index <- tibble(colnames(edak)))
View(edak_index)
edakCor <- edak[, -c(1,2,19)]
View(edakCor)
(edakCor_index <- tibble(colnames(edakCor)))
edakCor <- edakCor[, -c(4,6)]

corrCoe <- round(cor(edakCor, use = "complete.obs"), digits = 2)

corrCoe

heart_cor = edakCor

heart_cor = round(cor(heart_cor),1)
  
p.mat <- cor_pmat(heart_cor)
head(p.mat[, 1:4])
ggcorrplot(heart_cor)

edakNor <- edak

View(edakNor)

(edakNor_index <- tibble(colnames(edakNor)))
View(edakNor_index)

View(edak)
edakNor <- edakNor[,-c(19)]

edakNor[,c(1,2)] <- lapply(edakNor[,c(1,2)], as.factor)

edakNor <- edakNor[,-c(1,2)]

#Normalization function
normalize <- function(x){
  (x - min(x)) / (max(x) - min(x))
}

(edakNor_index <- tibble(colnames(edakNor)))
edakNor <- edakNor[,-c(4,6)]
View(edakNor_index)
str(edakNor)
edakNor <- normalize(edakNor)

clust_data_edak = select_if(edakNor,is.numeric)

View(clust_data_edak)

clust_data_edak <- clust_data_edak[,-c(2)] # dropping gross margin for clustering

edakNor <- edakNor[, -c(1,4,6,15)]

edakNor <- normalize(edakNor)

edakSta <- edak

(edakSta_index <- tibble(colnames(edakSta)))

View(edakSta)
View(edakSta_index)

edakSta <- edakSta[, -c(1,2,6,8,19)]

edakSta_scal <- scale(edakSta)

str(edakSta)
View(edakSta_scal)

edakSta_scale <- edakSta_scal[, -c(8)] #dropping revenue delta

clust_data_edak = select_if(edakSta,is.numeric)
View(clust_data_edak)

clust_data_edak <- clust_data_edak[, -c(8)]

clust_data_edak <- scale(clust_data_edak)
```

```{r}
set.seed(1)
kmeans_obj_edak = kmeans(clust_data_edak, centers = 3, algorithm = "Lloyd")
#kmeans_obj_nba

#Run Nbcluster
(nbclust_obj_edak = NbClust(data = clust_data_edak, method = "kmeans"))

freq_k_edak = nbclust_obj_edak$Best.nc[1,]
freq_k_edak = data.frame(freq_k_edak)

ggplot(freq_k_edak,
       aes(x = freq_k_edak)) +
  geom_bar() +
  scale_x_continuous(breaks = seq(0, 15, by = 1)) +
  scale_y_continuous(breaks = seq(0, 12, by = 1)) +
  labs(x = "Number of Clusters",
       y = "Number of Votes",
       title = "Earning Call Cluster Analysis")

```


```{r, echo=FALSE, warning = FALSE, include=FALSE}
#3 cluster
#Check how good clustering is
# Inter-cluster variance,
# "betweenss" is the sum of the distances between points 
# from different clusters.
num_edak = kmeans_obj_edak$betweenss

# Total variance, "totss" is the sum of the distances
# between all the points in the data set.
denom_edak = kmeans_obj_edak$totss

# Variance accounted for by clusters.
(var_exp_edak = num_edak / denom_edak)
```

```{r, echo=FALSE, warning = FALSE, include=FALSE}
# Now we are going to build a simple decision tree using the clusters as a feature

# reminder this is our model, using 3 clusters 
set.seed(1980)
kmeans_obj_edak = kmeans(clust_data_edak, centers = 3,
                        algorithm = "Lloyd")

#kmeans_obj_nba
# this is the output of the model. 
kmeans_obj_edak$cluster

#Append clusters to nbaNor
edakSta$clusters <- kmeans_obj_edak$cluster
#View(nbaNor)

clusters = as.factor(kmeans_obj_edak$cluster)
View(clust_data_edak)
typeof(clust_data_edak)
#View(clusters)

View(clusters)
#nba_cluster$clusters <- kmeans_obj_nba$cluster

edak_cluster = cbind(clust_data_edak,clusters)

#View(nba_cluster)

```

```{r, echo=FALSE, warning = FALSE}
#view(nba_cluster)
Ticker = edak$Ticker
QY = edak$`Quarter & Year`
RD = edak$`Revenue Delta`

View(edak)
range(edak$`Revenue Delta`)

#Add back salary and Player to nba_cluster
edak_cluster = cbind(edak_cluster, Ticker)
edak_cluster = cbind(edak_cluster, QY)
edak_cluster = cbind(edak_cluster, RD)

View(edak_cluster)
#view(nba_cluster)
```

```{r}
#View(edak_cluster)
typeof(edak_cluster)
#edak_cluster2 <- Map(intToUtf8, as.list(utf8ToInt(edak_cluster)))


edak_cluster2 <- as.data.frame(edak_cluster)

#range(edak_cluster2$`Polarity Mean`
#View(edak_cluster2)
plt <- ggplot(edak_cluster2,
              aes(x=`Revenue (E8)`,y=`Polarity Mean`)) +
  geom_point(aes(color = RD,
                 shape = as.factor(clusters)),
             size = 5) +
  ggtitle("NBA Salaries") +
  xlab("Assist") +
  ylab("Points") +
  scale_shape_manual(name = "Clusters",
                     labels = c("Cluster 1", "Cluster 2", "Cluster 3"),
                     values = c("1","2","3")) +
  
  scale_color_gradient(low = "green", high = "red") +
  theme(text = element_text(size = 15),
        panel.background = element_rect(fill = "white"),
        panel.grid.minor = element_line(color = NA),
        panel.grid.major = element_line(color = "grey",
                                        linetype = "dashed"),
        panel.border = element_rect(color = "black",
                                    fill = NA,
                                    size = 1))

plt
#dev.off()

```

```{r, echo=FALSE, warning = FALSE}
#3D Graph
#View(edak_cluster2)
#edak_cluster2$`Polarity Mean`

fig <- plot_ly(edak_cluster2,
               type = "scatter3d",
               mode = "markers", 
               symbol = ~clusters,
               x = ~`Gross Margin`,
               y = ~Subjectivity,
               z = ~`Polarity Mean`,
               color = ~edak_cluster2$clusters,
               text = ~paste('Ticker:', Ticker))

fig
#dev.off()
```
